{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tZ9zIlPmQ90"
   },
   "source": [
    "# Image Processing and Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AfLx4EcmQ93"
   },
   "source": [
    "## Instruction\n",
    "In this practical, student is required to perform the following image processing & computer vision functions. Images and video will be provided for the purposes.<br><br>\n",
    "__(A) Image processing:__ <br>\n",
    "    1) Read image<br>\n",
    "    2) Resize image<br>\n",
    "    3) Convert to grayscale image<br>\n",
    "    4) Convert to binary image<br>\n",
    "    5) Morphological operation<br>\n",
    "    6) Image denoise<br>\n",
    "    7) Edge detection<br>\n",
    "    8) Corner detection<br>\n",
    "    9) Image segmentation (manual): RGB range<br>\n",
    "    10) Image segmentation (auto): K-means<br>\n",
    "    11) Object detection using Haar Cascades<br>\n",
    "     \n",
    "__(B) Computer Vision:__ <br>\n",
    "    1) Intrusion Detection<br>\n",
    "    2) Live Video using Webcam<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_EolXzimQ94"
   },
   "source": [
    "# Section A: Image Processing\n",
    "\n",
    "Import necessary libraries. “cv2” is a well-known library (OpenCV) to perform image processing and video analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAqIaQ5AmQ95"
   },
   "outputs": [],
   "source": [
    "import \n",
    "import \n",
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gecNmPrVmQ96"
   },
   "source": [
    "## (1) Read Image\n",
    "“imread” is used to read an image in Python while “imshow” can be used to visualize an\n",
    "image output. The following lines read “Lenna.png” and visualize it in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdKOzdnemQ96",
    "outputId": "464ff8db-dff3-4652-e1d8-e638264de28f"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('')\n",
    "cv2.imshow('picOriLenna',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#OR\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "##Try to load your selfie or group photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that in Python we need to hold the visualization by using “cv2.waitKey(0)”\n",
    "until the user press any key for further processing. User may close all windows to release the\n",
    "memory by using “cv2.destroyAllWindows()”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_kB_PMfmQ97"
   },
   "source": [
    "## (2) Resize Image\n",
    "An image can be resized with the “resize” function. “fx” and “fy” indicate the scale that the\n",
    "image to be resized (Example: 0.5 means to downsize the image into ½ of the original size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REeWrUOymQ98",
    "outputId": "58b85013-d684-42ce-d220-fe2feee3ba07"
   },
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('')\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Resize the image\n",
    "imgResize = cv2.resize(img,None,fx=, fy=)\n",
    "cv2.imshow('picResized',imgResize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#OR\n",
    "# # Display the original image\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# # Display the resized image\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(cv2.cvtColor(imgResize, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Resized Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWeF3sDJmQ98"
   },
   "source": [
    "## (3) Convert to Grayscale\n",
    "An image can be converted to grayscale from color image with the following lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzVDi_LSmQ99"
   },
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(,) #take time to process RGB information\n",
    "cv2.imshow('picGray',gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Convert to Binary\n",
    "You can convert the image into binary image by setting the threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8sEGXY7mQ99",
    "outputId": "a815dc76-8d6c-4f4a-ff9a-56c8b1efa53f"
   },
   "outputs": [],
   "source": [
    "# Set the threshold value\n",
    "threshold_value = \n",
    "\n",
    "# Apply thresholding to convert to binary image\n",
    "binary_image = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the binary image\n",
    "cv2.imshow('Binary Image', binary_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#OR\n",
    "# # Display the original image\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# # Display the resized image\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(cv2.cvtColor(binary_image, cv2.THRESH_BINARY))\n",
    "# plt.title('Binary_image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZjlSUupmQ99"
   },
   "source": [
    "## (5) Morphological Operation\n",
    "\n",
    "Images may contain numerous imperfections. In particular, the binary regions produced by\n",
    "simple thresholding are distorted by noise and texture (example, gaps between the pixels).\n",
    "Morphological image processing pursues the goals of removing these imperfections by\n",
    "accounting for the form and structure of the image. Morphological operators often take a\n",
    "binary image and a structuring element as input and combine them using a set operator\n",
    "(intersection, union, inclusion, complement). They process objects in the input image based\n",
    "on characteristics of its shape, which are encoded in the structuring element. There are four\n",
    "common types of morphological operations which are; erosion, dilation, opening and closing.\n",
    "Following lines perform morphological operation with a Digit image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU9O46FNmQ9-"
   },
   "outputs": [],
   "source": [
    "# We use Digit image to perform morphological operation\n",
    "imgDigit = cv2.imread('')\n",
    "cv2.imshow('picOriDigit',imgDigit)\n",
    "\n",
    "# Erosion\n",
    "kernel = np.ones((,),np.uint8) #To define the structuring element\n",
    "erosion = cv2.erode(imgDigit,kernel,iterations = 1)\n",
    "cv2.imshow('picErosion',erosion) #https://www.geeksforgeeks.org/python-opencv-cv2-erode-method/\n",
    "\n",
    "# Dilation\n",
    "kernel = np.ones((,),np.uint8)\n",
    "dilation = cv2.dilate(imgDigit,kernel,iterations = 1)\n",
    "cv2.imshow('picDilation',dilation)\n",
    "\n",
    "# Opening - 2 step processes: erode > dilation\n",
    "kernel = np.ones((,),np.uint8)\n",
    "opening = cv2.morphologyEx(imgDigit, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('picOpening',opening)\n",
    "\n",
    "# Closing - 2 step processes: dilation > erode\n",
    "kernel = np.ones(,),np.uint8)\n",
    "closing = cv2.morphologyEx(imgDigit, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('picClosing',closing)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH7A5qlTmQ9-"
   },
   "source": [
    "You can also replace the imshow by pyplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9v2S68dmQ9-",
    "outputId": "b53e58bf-6ed2-48c4-8369-2211925adaf6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digit image\n",
    "imgDigit = cv2.imread('Digit3.png')\n",
    "\n",
    "# # Create a subplot grid for displaying images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Original Digit Image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(imgDigit, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Digit Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Erosion\n",
    "kernel = np.ones((, ), np.uint8)\n",
    "erosion = cv2.erode(imgDigit, kernel, iterations=1)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(cv2.cvtColor(erosion, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Erosion')\n",
    "plt.axis('off')\n",
    "\n",
    "# Dilation\n",
    "kernel = np.ones((, ), np.uint8)\n",
    "dilation = cv2.dilate(imgDigit, kernel, iterations=1)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(dilation, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Dilation')\n",
    "plt.axis('off')\n",
    "\n",
    "# Opening\n",
    "kernel = np.ones((, ), np.uint8)\n",
    "opening = cv2.morphologyEx(imgDigit, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(cv2.cvtColor(opening, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Opening')\n",
    "plt.axis('off')\n",
    "\n",
    "# Closing\n",
    "kernel = np.ones((, ), np.uint8)\n",
    "closing = cv2.morphologyEx(imgDigit, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(cv2.cvtColor(closing, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Closing')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL7_o_LumQ9_"
   },
   "source": [
    "## (6) Image Denoising\n",
    "Image noise is random (not present in the object imaged) variation of brightness or color\n",
    "information in images. It is an unwanted signal that could be an obstacle in the later\n",
    "processes (e.g feature extraction) and it might affect the overall system performance. Thus,\n",
    "it is important to have noise removal in the image preprocessing step. Following lines\n",
    "demonstrates noise removal by using three different filters (Average, Gaussian, and Median)\n",
    "on camera man image with salt and pepper noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLbddmd9mQ9_"
   },
   "source": [
    "References:<br>\n",
    "https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html<br>\n",
    "https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dACDbvTBmQ9_"
   },
   "outputs": [],
   "source": [
    "#Read and convert image into grayscale\n",
    "imgNoise = cv2.imread(\"\") #must remove the noise\n",
    "gray_imgNoise = cv2.cvtColor(imgNoise, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('picOriNoise',gray_imgNoise) #otherwise, treat it as feature>affect performance in object detection\n",
    "\n",
    "# Averaging filtering\n",
    "blurAverage = cv2.blur(gray_imgNoise,(,)) #try with different kernelsize\n",
    "cv2.imshow('picBlur', blurAverage)\n",
    "\n",
    "# Gaussian filtering\n",
    "blurGauss = cv2.GaussianBlur(gray_imgNoise,(,),0) #kernel size [height width], std deviation\n",
    "#https://www.tutorialkart.com/opencv/python/opencv-python-gaussian-image-smoothing/\n",
    "cv2.imshow('picBlurGauss',blurGauss)  #try and error\n",
    "\n",
    "# Median filtering\n",
    "blurMedian = cv2.medianBlur(gray_imgNoise,) #try and error\n",
    "cv2.imshow('picBlurMedian',blurMedian) #median works best 3x3\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvesFWYWmQ9_"
   },
   "source": [
    "You can also replace the imshow by pyplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8I86t1JmQ-A",
    "outputId": "fb5ba63a-b68f-438e-a66c-e9401d66038f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the noisy image\n",
    "imgNoise = cv2.imread(\"cameraman_noise.jpg\")\n",
    "gray_imgNoise = cv2.cvtColor(imgNoise, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a subplot grid for displaying images\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Original Noisy Image\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(gray_imgNoise, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Noisy Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Averaging filtering\n",
    "blurAverage = cv2.blur(gray_imgNoise, (, ))\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(blurAverage, cmap='gray')\n",
    "plt.title('Averaging Filtering')\n",
    "plt.axis('off')\n",
    "\n",
    "# Gaussian filtering\n",
    "blurGauss = cv2.GaussianBlur(gray_imgNoise, (, ), 0)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(blurGauss, cmap='gray')\n",
    "plt.title('Gaussian Filtering')\n",
    "plt.axis('off')\n",
    "\n",
    "# Median filtering\n",
    "blurMedian = cv2.medianBlur(gray_imgNoise, )\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(blurMedian, cmap='gray')\n",
    "plt.title('Median Filtering')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq6dlcLcmQ-C"
   },
   "source": [
    "## (7) Edge Detection\n",
    "Edge and corner are very useful image features commonly used for feature extraction and\n",
    "perform recognition in an image. Following lines used canny operator to extract the edge\n",
    "and Harris corner detector (next session) to extract the corner of the Chessboard image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zamuNvZJmQ-C"
   },
   "outputs": [],
   "source": [
    "filename = ''\n",
    "img = cv2.imread(filename)\n",
    "img = cv2.resize(img,None,fx=0.5, fy=0.5)\n",
    "cv2.imshow('picOriChessboard',img)\n",
    "\n",
    "# Edge detection using canny operator\n",
    "#https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html?highlight=edge\n",
    "\n",
    "edgesCanny = cv2.(img,100,200)  #setting of mask\n",
    "cv2.imshow('picEdgeCanny',edgesCanny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ''\n",
    "img = cv2.imread(filename)\n",
    "img = cv2.resize(img,None,fx=0.5, fy=0.5)\n",
    "cv2.imshow('picOriChessboard',img)\n",
    "\n",
    "# Corner detection using Harris corner detector\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.(gray,2,3,0.04)\n",
    "dst = cv2.dilate(dst,None) #result is dilated for marking the corners, not important\n",
    "img[dst>0.01*dst.max()]=[0,0,255] # Threshold for an optimal value, it may vary depending on the image. BGR red at the back\n",
    "cv2.imshow('picCornerHarris', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA-BVkmomQ-C"
   },
   "source": [
    "## (9) Image Segmentation (manual): RGB range\n",
    "1. Segment different elements from the map images (“map.png”) and visualize it in different\n",
    "windows such as lake, road, field, and housing area. Hint: you may refer to the following\n",
    "steps and distinguish each of them by using different range of RGB values.<br>\n",
    "a. Read “map.png” in python.<br>\n",
    "b. Insert the following code to extract the river. Understand the code and repeat the\n",
    "same process to extract road, field and housing area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cA54DApmQ-D"
   },
   "source": [
    "image segmentation based on the color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIY4M__KmQ-D"
   },
   "source": [
    "![](https://oi163.photobucket.com/albums/t281/kyin_album/map.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dc6CdtxmQ-D"
   },
   "source": [
    "Hint: You may check the RGB values for the map using the following website:\n",
    "http://imagecolorpicker.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2HsxeckmQ-D",
    "outputId": "d7921ae5-671d-4e10-9eff-1617292e6f3e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('')\n",
    "\n",
    "# Create a subplot grid for displaying images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Extract the river\n",
    "lower_river = np.array([])\n",
    "upper_river = np.array([])\n",
    "mask_river = cv2.inRange(img, lower_river, upper_river)\n",
    "river = cv2.bitwise_and(img, img, mask=mask_river)\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(river, cv2.COLOR_BGR2RGB))\n",
    "plt.title('River')\n",
    "plt.axis('off')\n",
    "\n",
    "# Extract the road\n",
    "lower_road = np.array([])\n",
    "upper_road = np.array([])\n",
    "mask_road = cv2.inRange(img, lower_road, upper_road)\n",
    "road = cv2.bitwise_and(img, img, mask=mask_road)\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.imshow(cv2.cvtColor(road, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Road')\n",
    "plt.axis('off')\n",
    "\n",
    "# Extract the field\n",
    "lower_field = np.array([])\n",
    "upper_field = np.array([])\n",
    "mask_field = cv2.inRange(img, lower_field, upper_field)\n",
    "field = cv2.bitwise_and(img, img, mask=mask_field)\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.imshow(cv2.cvtColor(field, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Field')\n",
    "plt.axis('off')\n",
    "\n",
    "# Extract the houseing_area\n",
    "lower_field = np.array([])\n",
    "upper_field = np.array([])\n",
    "mask_field = cv2.inRange(img, lower_field, upper_field)\n",
    "houseing_area = cv2.bitwise_and(img, img, mask=mask_field)\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.imshow(cv2.cvtColor(houseing_area, cv2.COLOR_BGR2RGB))\n",
    "plt.title('houseing_area')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10) Image Segmentation (Auto): K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoHKjnCYmQ-D",
    "outputId": "5cf75cdf-46ed-49f2-8222-0feb1783d7ec"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('')\n",
    "\n",
    "# Reshape the image to a 2D array of pixels\n",
    "pixels = img.reshape((-1, 3))  # Modify to (-1, 3) if color image\n",
    "\n",
    "# Convert to float32\n",
    "pixels = np.float32(pixels)\n",
    "\n",
    "# Define the criteria and flags for k-means\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "k =   # Number of clusters\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "# Apply k-means clustering\n",
    "ret, label, center = cv2.kmeans(pixels, k, None, criteria, 20, flags)  # Increase the iteration count\n",
    "\n",
    "# Convert the center values back to uint8\n",
    "center = np.uint8(center)\n",
    "\n",
    "# Separate pixels based on their labels (clusters)\n",
    "segmented_imgs = [np.zeros_like(img) for _ in range(k)]\n",
    "\n",
    "for i in range(k):\n",
    "    cluster_mask = (label == i).reshape(img.shape[:2])\n",
    "    segmented_imgs[i][cluster_mask] = img[cluster_mask]\n",
    "\n",
    "# Display the original image and segmented images\n",
    "plt.figure(figsize=(15, 10))  # Increase the figure size\n",
    "\n",
    "plt.subplot(2, 3, 1)  # Adjust the subplot layout\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(k):\n",
    "    plt.subplot(2, 3, i + 2)  # Adjust the subplot layout\n",
    "    plt.imshow(cv2.cvtColor(segmented_imgs[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Cluster {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()  # Automatically adjust subplot spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENzWRRKemQ-h"
   },
   "source": [
    "## (11) Object detection using Haar Cascades\n",
    "Haar Cascade classifiers are an effective way for object detection. This method was proposed by Paul Viola and Michael Jones in their paper Rapid Object Detection using a Boosted Cascade of Simple Features. Haar Cascade is a machine learning-based approach where a lot of positive and negative images are used to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8oKoxDnmQ-h",
    "outputId": "d03bfb2d-688f-4cf9-f1d1-d7ce6c92f951"
   },
   "outputs": [],
   "source": [
    "# Opening image\n",
    "img = cv2.imread(\"\")\n",
    "\n",
    "# OpenCV opens images as BRG but we want it as RGB We'll also need a grayscale version\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Use minSize because for not bothering with extra-small dots that would look like STOP signs\n",
    "stop_data = cv2.('')\n",
    "\n",
    "found = stop_data.detectMultiScale(img_gray, minSize =(20, 20))  # detectMultiScale() method of the CascadeClassifier is used to detect objects in the grayscale image (img_gray). The method returns a list of rectangles indicating the regions where objects were detected.\n",
    "print (found)\n",
    "# Don't do anything if there's no sign\n",
    "amount_found = len(found)\n",
    "\n",
    "if amount_found != 0:\n",
    "\n",
    "    # There may be more than one sign in the image\n",
    "    for (x, y, width, height) in found:\n",
    "\n",
    "        # We draw a green rectangle around every recognized sign\n",
    "        cv2.rectangle(img_rgb, (x, y),\n",
    "                      (x + height, y + width),\n",
    "                      (0, 255, 0), 5)\n",
    "\n",
    "# Creates the environment ofthe picture and shows it\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B: Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('')        #complete this\n",
    "\n",
    "fgbg = cv2.                 #complete this\n",
    "\n",
    "fgmask_Threshold = 0.3 #apply threshold of 30% of the screen is filled with unintended object\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame) #remove the background and obtain foreground mask\n",
    "    #print(fgmask)\n",
    "\n",
    "    #Intrusion detection\n",
    "    if ret==True:\n",
    "        fgmask_Filter = fgmask > 1\n",
    "        #print (fgmask_Filter)\n",
    "        fgmask_Intrusion = sum(sum(fgmask_Filter))     #this is just algorithm to identify intruder, you can creat your own method based on logical thinking\n",
    "        #print (fgmask_Intrusion)\n",
    "        if float(fgmask_Intrusion)/(float(120)*float(160)) > fgmask_Threshold: #total pixel of moving object/total size  > 30% then assume intrusion\n",
    "            intrusion = 1\n",
    "        else:\n",
    "            intrusion = 0\n",
    "\n",
    "        print (intrusion)\n",
    "\n",
    "        cv2.imshow('frame',fgmask)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release() # Release the capture when everything is done\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Live Video using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "#   Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "       # Our operations on the frame come here\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "       # Display the resulting frame\n",
    "        cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release() # Release the capture when everything is done\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
