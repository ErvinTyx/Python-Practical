{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H6ty0er_M1m"
   },
   "source": [
    "# Machine Learning: Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwcohRsf_M1u"
   },
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jC6FF14c_M1u"
   },
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10qcHkjI_M1v"
   },
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cszZFWTd_M1v"
   },
   "source": [
    "# <font color=\"blue\"> Project 1: House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqfU8nTm_M1v"
   },
   "source": [
    "In this example, we'll use a linear regression model to predict housing prices based on 1 feature.\n",
    "\n",
    "First, make sure you have scikit-learn installed. You can install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2jOAF7i_M1w"
   },
   "outputs": [],
   "source": [
    "pip install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about scikit-learn : [Scikit-learn Documentation](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HA16nJku_M1y"
   },
   "source": [
    "## Step 1: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZVIZHnG_M1y"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import\n",
    "from sklearn.linear_model import \n",
    "from sklearn.metrics import \n",
    "\n",
    "# Sample dataset: housing prices (target) based on house size (feature)\n",
    "house_sizes = np.array([550, 600, 650, 700, 750, 800, 850, 900, 950, 1000])\n",
    "prices = np.array([300000, 410000, 530000, 510000, 540000, 610000, 730000, 760000, 830000, 860000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePfW9hvu_M1z"
   },
   "outputs": [],
   "source": [
    "#plot graph prices against house_prices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   #https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(house_sizes, prices, color='', label='Data Points')\n",
    "plt.xlabel('House Size')\n",
    "plt.ylabel('Prices')\n",
    "plt.title('House Prices vs. House Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_kESJc7_M1z"
   },
   "source": [
    "## Step 2 & 3 : Feature Extraction and Split the data (into training and testing set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AJw9y30_M10"
   },
   "outputs": [],
   "source": [
    "# Reshape the feature array to match the input format required by scikit-learn\n",
    "X =                         #reshape the array into a single column (1 column) and to infer the number of rows (-1 rows) \n",
    "print (X)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, prices, test_size= , random_state=42)\n",
    "print (X_test)   #these 2 data will be used to test the model\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmmgSpE9_M10"
   },
   "source": [
    "## Step 4: Fit model and predict outcomes [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGZuQoGD_M10"
   },
   "outputs": [],
   "source": [
    "# Create the linear regression model\n",
    "model = \n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Formatting X_test\n",
    "formatted_X_test = [\"%.2f\" % x for x in X_test]\n",
    "print(formatted_X_test)\n",
    "\n",
    "# Formatting y_pred\n",
    "formatted_y_pred = [\"%.2f\" % y for y in y_pred]\n",
    "print(formatted_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is the equation of the linear regression model\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficient:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Construct the equation string\n",
    "equation = f\"y = {model.intercept_} + {model.coef_[0]} * X\"\n",
    "print(\"Linear Regression Equation:\", equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF7M8hcM_M11"
   },
   "source": [
    "## Step 5: Evaluate the model [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sun9s3g4_M11"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) as a measure of the model's performancemse = mean_squared_error(y_test, y_pred)\n",
    "# Display the MSE with two decimal places using string formatting\n",
    "formatted_mse = \"%.2f\" % mse\n",
    "print(f\"Mean Squared Error: {formatted_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2plqwoLzjGf"
   },
   "source": [
    "# Step 6: Predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCyQHYWZx2tu"
   },
   "outputs": [],
   "source": [
    "# Assuming you have a single unseen data point represented as a list\n",
    "unseen_data = \n",
    "\n",
    "# Reshape the unseen_data to a 2D array\n",
    "unseen_data_reshaped = np.array(unseen_data).reshape(1, -1)\n",
    "\n",
    "# Predict the target value for the unseen data point\n",
    "predicted_value = \n",
    "\n",
    "# Print the predicted value\n",
    "print(f\"Predicted Value: {predicted_value[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYeGeeAa_M13"
   },
   "source": [
    "# <font color=\"blue\"> Project 2: Spam Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7T-8Lyzg_M13"
   },
   "source": [
    "## Step 1: Prepare the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1711418289679,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "MoZh8Zqo_M13",
    "outputId": "ea5c6a7b-9ca0-4a39-c716-9d1a10481bf1"
   },
   "outputs": [],
   "source": [
    "# make sure the data is labeled\n",
    "import pandas as pd\n",
    "data = pd.read_table('',encoding='windows-1252', header=None)\n",
    "data.columns = ['', '']\n",
    "print(data.head())\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1711418299405,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "BL7xpjnm_M13",
    "outputId": "ae7b5da7-2921-4cab-cbba-167d6feafd94"
   },
   "outputs": [],
   "source": [
    "# remove words with numbers, punctuation and capital letters\n",
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)  #another method function\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "data['text'] = data.text.map(alphanumeric).map(punc_lower)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlec3iHj_M14"
   },
   "source": [
    "## Step 2: Split the data (into training and testing set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17gs2b4B_M14"
   },
   "source": [
    "<Font color=\"Blue\">__Input__: Features, Predictors, Independent Variables, X's\n",
    "<Font color=\"orange\">__Outputs__: Label, Outcome, Dependent Variable, Y\n",
    "    \n",
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1711418317733,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "BnXJffXG_M14"
   },
   "outputs": [],
   "source": [
    "# split the data into feature and label\n",
    "X = data.text # inputs into model\n",
    "y = data.label # output of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCRkjjgO_M14"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlwtMIGM_M15"
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf0fW6-Z_M15"
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0kr3xpT_M15"
   },
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PojygMv-_M15"
   },
   "source": [
    "# Split the data [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1711418388449,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "4fF3L8xn_M15"
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# test size = 30% of observations, which means training size = 70% of observations\n",
    "# random state = 42, so we all get the same random train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D6j4b8__M16"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sb9orvle_M16"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbcwZ-8V_M16"
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzoVCOcN_M16"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUxZZ_K3_M2P"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lilnFM5u_M2Q"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GnESdi9_M2Q"
   },
   "source": [
    "## Step 3: Numerically encode the input data [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKFWPkcF_M2Q"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1711418409733,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "ILF9pyie_M2Q",
    "outputId": "60ddfea9-81d8-4b73-d169-b5ca13efd5a9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test) # transform uses the same vocab and one-hot encodes\n",
    "# print the dimensions of the training set (text messages, terms)\n",
    "print(X_train_cv.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(cv, 'countvectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1711418412675,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "uT9OC-fy_M2R",
    "outputId": "99a65a2c-a052-484f-f228-308b63cd3924"
   },
   "outputs": [],
   "source": [
    "type(X_train_cv)\n",
    "import scipy.sparse\n",
    "pd.DataFrame.sparse.from_spmatrix(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-g-pB0L_M2R"
   },
   "outputs": [],
   "source": [
    "help(cv.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS3Im8c0_M2R"
   },
   "source": [
    "## Step 4: Fit model and predict outcomes [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1711418436019,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "ekdoA8rf_M2R",
    "outputId": "9cb433b7-44dc-4070-f7b0-008f74943c76"
   },
   "outputs": [],
   "source": [
    "# Use a logistic regression model (categorical)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X_train_cv, y_train) #= train\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "y_pred_cv = lr.predict(X_test_cv)\n",
    "y_pred_cv # The output is all of the predictions/ labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCHg9Bdm_M2S"
   },
   "source": [
    "## Step 5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPds_0Yc_M2S"
   },
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hir46DGX_M2S"
   },
   "source": [
    "# Step 5: Evaluate the model [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1711418444562,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "c3KZwwpH_M2S",
    "outputId": "1042d672-29ec-4398-86bc-f3bfca73665c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "#Provided you are running IPython, the %matplotlib inline will make your plot outputs appear and be stored within the notebook\n",
    "cm = confusion_matrix(y_test, y_pred_cv)   #y_test is the label of testing data, y_pred_cv is the predicted ans from the ML with testing set\n",
    "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'],\n",
    "annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "true_neg, false_pos = cm[0]\n",
    "false_neg, true_pos = cm[1]\n",
    "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muhACP9j_M2S"
   },
   "source": [
    "## Step 6: Predict new input [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1711418879974,
     "user": {
      "displayName": "CHING PANG GOH",
      "userId": "03150219032412111071"
     },
     "user_tz": -480
    },
    "id": "eyI1BQfT_M2S",
    "outputId": "7f998fd8-eb59-41e3-e3b6-1717fecfc3ef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "Sentence1 = \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st\"\n",
    "df = pd.DataFrame(columns=[Sentence1])\n",
    "df.head()\n",
    "\n",
    "Snew = cv.transform(df)\n",
    "result = lr.predict(Snew)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBrwdu73_M2T"
   },
   "source": [
    "# <font color=\"blue\"> __Naive Bayes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQQD4dNg_M2T"
   },
   "source": [
    "# Naive Bayes [code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VEvQxB8_M2T"
   },
   "outputs": [],
   "source": [
    "# Use a Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "nb = MultinomialNB()\n",
    "# Train the model\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfxP9z8f_M2T"
   },
   "source": [
    "# Naive Bayes: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXAXX1Yu_M2T"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_cv_nb)\n",
    "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'],\n",
    "annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "true_neg, false_pos = cm[0]\n",
    "false_neg, true_pos = cm[1]\n",
    "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))\n",
    "\n",
    "NBscore = nb.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjZKpaYB_M2U"
   },
   "source": [
    "# <font color=\"blue\"> Project 3: Review Rating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will be using the same review data set from Kaggle for this exercise. The product we'll focus on this time is a cappuccino cup.\n",
    "\n",
    "The following code will help you load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE_TXd4P_M2U"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIpt2oBc_M2U"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VngrUEeE_M2U"
   },
   "source": [
    "### Question 1\n",
    "\n",
    "- Determine how many reviews there are in total.\n",
    "\n",
    "\n",
    "Use the preprocessing code below to clean the reviews data before moving on to modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4rA-xhA_M2V"
   },
   "outputs": [],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = \n",
    "punc_lower =\n",
    "\n",
    "data['reviews'] = data.reviews.map(alphanumeric).map(punc_lower)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXewp_k2_M2V"
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zJ7gQiN_M2V"
   },
   "source": [
    "### Question 2: Classsification *(20% testing, 80% training)*\n",
    "\n",
    "Processes for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DzMCwA6_M2V"
   },
   "source": [
    "### <font color=\"Blue\">Step 1:</font> Prepare the data (identify the feature and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QmNMBni_M2V"
   },
   "outputs": [],
   "source": [
    "# split the data into feature and label\n",
    "X = data.reviews # inputs into model\n",
    "y = data.stars # output of model\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKAs3CwM_M2W"
   },
   "source": [
    "### <font color=\"Blue\">Step 2:</font> Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWwVTj6h_M2W"
   },
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=, random_state=42)\n",
    "# test size = 30% of observations, which means training size = 70% of observations\n",
    "# random state = 42, so we all get the same random train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9dCTtWg_M2W"
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBkN1yoN_M2W"
   },
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvxHPOF4_M2W"
   },
   "source": [
    "### <font color=\"Blue\">Step 3:</font> Vectorize the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXd0Li3o_M2X"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='')\n",
    "X_train_cv = \n",
    "X_test_cv =                  # transform uses the same vocab and one-hot encodes\n",
    "# print the dimensions of the training set (text messages, terms)\n",
    "print(X_train_cv.toarray().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFAhXYDS_M2X"
   },
   "source": [
    "### <font color=\"Blue\">Step 4:</font> Idenfity the model/ classifier to be used. Feed the train data into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0wGpeSV_M2X"
   },
   "source": [
    "### - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBdyQv2r_M2X"
   },
   "outputs": [],
   "source": [
    "# Use a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up9NiksJ_M2Y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob4vtOQG_M2Y"
   },
   "source": [
    "### - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLTWggkm_M2Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7wMHaSm_M2Y"
   },
   "source": [
    "### - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XooN2C_8_M2Y"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgKC-BuN_M2Z"
   },
   "source": [
    "### - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lm5lN875_M2Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az5rD363_M2Z"
   },
   "source": [
    "### - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7d7ZhSD_M2Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN4NMmrq_M2Z"
   },
   "source": [
    "### -  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBPs-aia_M2a"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvD9FyXf_M2a"
   },
   "source": [
    "### <font color=\"Blue\">Step 5:</font> Evaluate the Model - Accuracy Measurement\n",
    "Generate the accuracy scores for Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-ib3bZ2_M2a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lra = accuracy_score(y_test, y_pred_LR)\n",
    "svm = accuracy_score(y_test, y_pred_svm)\n",
    "dt = accuracy_score(y_test, y_pred_dt)\n",
    "rf = accuracy_score(y_test, y_pred_rf)\n",
    "knn = accuracy_score(y_test, y_pred_knn)\n",
    "nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Accuracy score for LR: %.2f\" % lra)\n",
    "print(\"Accuracy score for SVM: %.2f\" % svm)\n",
    "print(\"Accuracy score for DT: %.2f\" % dt)\n",
    "print(\"Accuracy score for RF: %.2f\" % rf)\n",
    "print(\"Accuracy score for KNN: %.2f\" % knn)\n",
    "print(\"Accuracy score for NB: %.2f\" % nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTTf68iW_M2a"
   },
   "source": [
    "__Example Output:__\n",
    "- Accuracy score for LR  = 0.1651\n",
    "- Accuracy score for SVM = 0.5413\n",
    "- Accuracy score for DT  = 0.5505\n",
    "- Accuracy score for RF  = 0.5872\n",
    "- Accuracy score for KNN = 0.5963\n",
    "- Accuracy score for NB  = 0.6514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1yxEuUd_M2b"
   },
   "source": [
    "### Question 3\n",
    "Predict the rate of this review,\n",
    "\n",
    "<font color=\"blue\">__\"like Cafe Vienna instant coffee products with the convenience of Keurig. All authorized on-line sellers cannot carry them\"__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke-mMhKX_M2b"
   },
   "source": [
    "by using Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGrDnUYw_M2b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "S2 = \"\"\n",
    "df = pd.DataFrame(columns=[])\n",
    "df.head()\n",
    "\n",
    "Snew = cv.transform(df)\n",
    "lry = lr.predict(Snew)\n",
    "print(lry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjaE6Wv4_M2b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "user_input = input(\"Enter a sentence: \")\n",
    "df = pd.DataFrame(columns=[])\n",
    "df.head()\n",
    "\n",
    "Snew = cv.transform(df)\n",
    "lry = lr.predict(Snew)\n",
    "print(lry)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
