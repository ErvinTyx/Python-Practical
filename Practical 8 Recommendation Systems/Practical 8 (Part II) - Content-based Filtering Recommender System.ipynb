{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKVG2QbjE4Uv"
   },
   "source": [
    "# Practical 8 (Part II) - Recommender System (Content-based Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VuCrJd0E4Uw"
   },
   "source": [
    "Content-Based Recommendations systems are the systems that look for similarity before recommending something. To understand how similarity between different products is computed, there are different techniques or similarity measures that are used to compute the similarity, such as Euclidean distance and cosine similarity. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations.\n",
    "\n",
    "\n",
    "This practical helps you to learn how to build a basic model of content-based recommender systems using the Movies Data set that is publicly available on Kaggle. You will learn how to build a system that recommends movies that are similar to a particular movie. To achieve this, you will compute pairwise cosine similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score threshold.\n",
    "\n",
    "Reference: \n",
    "\n",
    "Full dataset can be downloaded here: https://www.kaggle.com/rounakbanik/the-movies-dataset?select=movies_metadata.csv\n",
    "\n",
    "The reference of this practical: https://www.datacamp.com/community/tutorials/recommender-systems-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9e4rpeNE4Uw"
   },
   "source": [
    "## Section 1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7aUhEQj7E4Ux"
   },
   "source": [
    "\"movies_metadata.csv\" contains information on ~45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, genre, revenue, release dates, languages, production countries, and companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtyIA0yHE4Ux"
   },
   "source": [
    "1. Let's load your movies metadata dataset into a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "error",
     "timestamp": 1598199323921,
     "user": {
      "displayName": "CHI WEE TAN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GijHp2AsEs6M_zt6H3EmAOa-hTcKiWeIJFFhu_Y=s64",
      "userId": "13878856117499750324"
     },
     "user_tz": -480
    },
    "id": "RAeC25MgE4Uz",
    "outputId": "8c5dfe22-15ed-4df0-c6eb-fa70d0bfe575"
   },
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Movies Metadata\n",
    "metadata = pd.read_csv('', low_memory=True)           #read movies_metadata.csv\n",
    "\n",
    "# Print the first three rows\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8JqhFyeE4U3"
   },
   "outputs": [],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGu41wRAE4U5"
   },
   "source": [
    "There are 45466 rows and 24 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbVHHCCcE4U6"
   },
   "source": [
    "2.  Let's inspect the plots of a few movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dX_XsEdE4U6",
    "outputId": "1bbbd95a-4db9-4d81-f9f4-00c8e98f672a"
   },
   "outputs": [],
   "source": [
    "#The plot description is available to you as the overview feature in your metadata dataset. \n",
    "metadata['overview'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAleWRjYE4U8"
   },
   "source": [
    "## Section 2 Features Generation\n",
    "\n",
    "Now we have a Natural Language Processing problem to solve. Therefore we need to extract some kind of features from the above text data before we can compute the similarity and/or dissimilarity between them. To do this, we need to compute the word vectors of each overview or document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTF_0idVE4U9"
   },
   "source": [
    "As the name suggests, word vectors are vectorized representation of words in a document. The vectors carry a semantic meaning with it. The following section shows how we could use Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each document. \n",
    "\n",
    "TF-IDF will produce a matrix where each column represents a word in the overview vocabulary (all the words that appear in at least one document), and each column represents a movie, as before. The TF-IDF score is the frequency of a word occurring in a document, down-weighted by the number of documents in which it occurs. This is done to reduce the importance of words that frequently occur in plot overviews and, therefore, their significance in computing the final similarity score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFlWqylfE4U9"
   },
   "source": [
    "3. Now, let's use scikit-learn built-in TfIdfVectorizer class to produce the TF-IDF matrix, by following the steps below:\n",
    "\n",
    "(i) Import the Tfidf module using scikit-learn;\n",
    "\n",
    "(ii) Remove stop words like 'the', 'an', etc. since they do not give any useful information about the topic;\n",
    "\n",
    "(iii) Replace not-a-number values with a blank string; \n",
    "\n",
    "(iv) Finally, construct the TF-IDF matrix on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vc5LCSWaE4U9",
    "outputId": "7d7db938-3755-4ebb-fcb9-79d4ca8c9833"
   },
   "outputs": [],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import                   # import TfidfVectorizer as feature extraction\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object.\n",
    "tfidf = TfidfVectorizer(stop_words='')                    #  Remove all english stop words such as 'the'\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "metadata['overview'] = metadata['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KmG9TZrE4VB"
   },
   "source": [
    "There are 75,827 different vocabularies or words (features) in the dataset that contains 45,466 movies.\n",
    "\n",
    "4. Let's check out some of the the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIcsXElCE4VB",
    "outputId": "caa07c51-eba9-4091-a72d-2b1ffe035dad"
   },
   "outputs": [],
   "source": [
    "#Array mapping from feature integer indices to feature name.\n",
    "tfidf.get_feature_names_out()[5000:5010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Zmnz4NTE4VE"
   },
   "source": [
    "With the matrix, we can now use the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies. Cosine similarity score is used since it is independent of magnitude and is relatively easy and fast to calculate.\n",
    "Note that there are metrics that you can use for this, such as the manhattan, euclidean, the Pearson, other than cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvFwEGVKE4VE"
   },
   "source": [
    "5. Since TF-IDF vectorizer is used, calculating the dot product between each vector will directly give you the cosine similarity score. Therefore, you will use sklearn's <i>linear_kernel()</i> instead of <i>cosine_similarities()</i> since it is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PIAy37oE4VE"
   },
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpHGt3oGE4VG",
    "outputId": "30637702-633f-4a30-8654-bade99068203"
   },
   "outputs": [],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIxA05T_E4VI"
   },
   "source": [
    "The above returns a matrix of shape 45466x45466, which means each movie overview cosine similarity score with every other movie overview. Hence, each movie will be a 1x45466 column vector where each column will be a similarity score with each movie. Sample matrix is as follows:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aZHMf7zE4VJ",
    "outputId": "0427f7be-7f8d-4c34-8cb6-1c0dc0422c94"
   },
   "outputs": [],
   "source": [
    "#observing the first 6 rows and 6 columns\n",
    "for i in range(6):\n",
    "    print(cosine_sim[i][:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEOZFrm2E4VM"
   },
   "source": [
    "6. Next, we need to define a function that takes in a movie title as an input and outputs a list of the 10 most similar movies. Firstly, for this, you need a reverse mapping of movie titles and DataFrame indices. In other words, we are generating the ID for each movie title using index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un5kFaPNE4VM",
    "outputId": "f265d47a-595c-490b-8695-47ac2ebf450b"
   },
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
    "\n",
    "#check the first 10 indices\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPqhFpZaE4VP"
   },
   "source": [
    "## Section 3 Content-Based Filtering Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBppfWdbE4VP"
   },
   "source": [
    "Now let's build a content filtering recommender. These are the following steps to follow:\n",
    "\n",
    "(i) Get the index of the movie given its title.\n",
    "\n",
    "(ii) Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position, and the second is the similarity score.\n",
    "\n",
    "(iii) Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n",
    "\n",
    "(iv) Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n",
    "\n",
    "(v) Return the titles corresponding to the indices of the top elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mhCmCDlDE4VP"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return metadata['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfK5mr56E4VR",
    "outputId": "5183b9b4-823a-4779-8374-d4adfe8beffc"
   },
   "outputs": [],
   "source": [
    "get_recommendations('')                 #obtain the movie that has the similarity to user input e.g. The Dark Knight Rises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTC2oUNrE4VT"
   },
   "source": [
    "Now you may try out other movie titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjT67hO3E4VT"
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "synbW6LBE4VU"
   },
   "source": [
    "Q1. <b>Building Credits, Genres, and Keywords Based Recommender</b>: You are required to build a recommender system based on the following metadata: the 3 top actors, the director, related genres, and the movie plot keywords.\n",
    "\n",
    "Reference: https://www.datacamp.com/community/tutorials/recommender-systems-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mISChU2ME4VU"
   },
   "source": [
    "Q2. <b>Popularity filter</b>: Build a recommender would take the 30 most similar movies, calculate the weighted ratings (using the IMDB formula from above), sort movies based on this rating, and return the top 10 movies."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practical 8 (Part II) - Content-based Filtering Recommender System.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
